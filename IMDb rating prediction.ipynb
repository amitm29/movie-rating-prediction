{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXfilePath = './Dataset/imdb_trainX.txt'\n",
    "trainYfilePath = './Dataset/imdb_trainY.txt'\n",
    "\n",
    "testXfilePath  = './Dataset/imdb_testX.txt'\n",
    "testYfilePath  = './Dataset/imdb_testY.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trainXfilePath) as f:\n",
    "    reviews = f.readlines()\n",
    "X_train = []\n",
    "for review in reviews:\n",
    "    X_train.append(review)\n",
    "\n",
    "    \n",
    "with open(trainYfilePath) as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "Y_train = []\n",
    "for label in labels:\n",
    "    Y_train.append(int(label))\n",
    "    \n",
    "\n",
    "with open(testXfilePath) as f:\n",
    "    reviews = f.readlines()\n",
    "\n",
    "X_test = []\n",
    "for review in reviews:\n",
    "    X_test.append(review)\n",
    "\n",
    "\n",
    "with open(testYfilePath) as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "Y_test = []\n",
    "for label in labels:\n",
    "    Y_test.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating own Multinomial Naive Bayes model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for stop word removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sw = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#returns \"words\" from the input text after stemming and removing stop words \n",
    "def get_useful_words(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"<br />\",\"\")\n",
    "    \n",
    "    #tokenization\n",
    "    word_list = tokenizer.tokenize(text)\n",
    "    \n",
    "    #stop word removal\n",
    "    useful_words = [w for w in word_list if w not in sw]\n",
    "    \n",
    "    #stemming\n",
    "    stemmed_words = [ps.stem(w) for w in useful_words]\n",
    "    \n",
    "    return stemmed_words\n",
    "\n",
    "#returns \"text\" after cleaning i.e. removing stop words and stemming \n",
    "def getCleanReview(review):\n",
    "    \n",
    "    review = review.lower()\n",
    "    review = review.replace(\"<br /><br />\",\" \")\n",
    "    \n",
    "    #Tokenize\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [token for token in tokens if token not in sw]\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train our Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,Y_train):\n",
    "    #initialize number of training documents read till now as 0\n",
    "    N = 0\n",
    "\n",
    "    #initialize the count of each class's documents as 0\n",
    "    Nc = []\n",
    "    index = 0\n",
    "    #dictionary which maps each label's value with its corresponding index in Nc\n",
    "    label_index = {}\n",
    "    #list of dictionaries of each class words mapped to their count(i.e. frequency)\n",
    "    count_w_c = []\n",
    "    #list of count of all words of each class\n",
    "    count_c = []\n",
    "    #vocabulary\n",
    "    vocab = {}\n",
    "\n",
    "    for i in np.unique(Y_train):\n",
    "        Nc.append(0)\n",
    "        count_c.append(0)\n",
    "        count_w_c.append({})\n",
    "        label_index[i] = index\n",
    "        index += 1\n",
    "\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        N += 1\n",
    "        l_index = label_index[Y_train[i]]\n",
    "        Nc[l_index] += 1\n",
    "\n",
    "        #reading a document\n",
    "        document = X_train[i]\n",
    "\n",
    "        #extracting words from the document (and removing stop words and stemming)\n",
    "        words = get_useful_words(document)\n",
    "#         words = tokenizer.tokenize(document.lower())\n",
    "\n",
    "        for word in words:\n",
    "            count_c[l_index] += 1\n",
    "            try:\n",
    "                count_w_c[l_index][word] += 1\n",
    "                vocab[word] +=1\n",
    "            except:\n",
    "                count_w_c[l_index][word] = 1\n",
    "                vocab[word] =1\n",
    "    return N, Nc, vocab, label_index, count_w_c, count_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.5 s, sys: 13.3 ms, total: 52.5 s\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N, Nc, vocab, label_index, count_w_c, count_c = train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "[5100, 2284, 2420, 2696, 2496, 3009, 2263, 4732]\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 7: 4, 8: 5, 9: 6, 10: 7}\n",
      "[547932, 265451, 312604, 355564, 342091, 399534, 290496, 510811]\n"
     ]
    }
   ],
   "source": [
    "print(N)\n",
    "print(Nc)\n",
    "print(label_index)\n",
    "# print(count_w_c)\n",
    "print(count_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(label_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29007"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = np.max(np.asarray(list(vocab.values())))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the prediction on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_prob(label):\n",
    "    return Nc[label_index[label]]/N\n",
    "\n",
    "\n",
    "def predict(xtest):\n",
    "#     words = tokenizer.tokenize(xtest.lower())\n",
    "    words = get_useful_words(xtest)\n",
    "    \n",
    "    classes = list(label_index.keys())\n",
    "    post_prob = []\n",
    "    for label in classes:\n",
    "        log_likelihood = 0\n",
    "        total_words = count_c[label_index[label]] + vocab_size\n",
    "        for word in words:\n",
    "            try:\n",
    "                count_word = count_w_c[label_index[label]][word] + 1\n",
    "            except:\n",
    "                count_word = 1\n",
    "            finally:\n",
    "                log_likelihood += np.log2(count_word/total_words)\n",
    "                \n",
    "        prior = prior_prob(label)\n",
    "        \n",
    "        post = log_likelihood + np.log2(prior)\n",
    "        post_prob.append(post)\n",
    "    \n",
    "#     print(post_prob)\n",
    "    pred = np.argmax(post_prob)\n",
    "    return pred\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "10\n",
      "9\n",
      "CPU times: user 4.48 ms, sys: 19 Âµs, total: 4.5 ms\n",
      "Wall time: 3.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = 15\n",
    "pred = predict(X_test[index])\n",
    "print(pred)\n",
    "print(np.unique(Y_train)[pred])\n",
    "print(Y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predict(X_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find out the accuracy on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(X_test,Y_test):\n",
    "    correct = 0\n",
    "    itr = 0\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        itr += 1\n",
    "        pred = predict(X_test[i])\n",
    "        if Y_test[i] == np.unique(Y_train)[pred]:\n",
    "            correct += 1\n",
    "        print('Iterations : %d      Accuracy : %.4f'%(itr,(correct/float(itr))), end='\\r')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3754\n",
      "\n",
      "CPU times: user 1min 56s, sys: 1.25 s, total: 1min 57s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3647\n",
      "\n",
      "CPU times: user 1min 3s, sys: 928 ms, total: 1min 4s\n",
      "Wall time: 60 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3765\n",
      "\n",
      "CPU times: user 1min 47s, sys: 1.32 s, total: 1min 48s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random guess accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(Y_test):\n",
    "    correct = 0\n",
    "    itr = 0\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        itr += 1\n",
    "        pred = random.randint(10)\n",
    "        if Y_test[i] == pred:\n",
    "            correct += 1\n",
    "    print('Iterations : %d      Accuracy : %.4f'%(itr,(correct/float(itr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.0799\n",
      "CPU times: user 44.5 ms, sys: 3.86 ms, total: 48.3 ms\n",
      "Wall time: 66.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn MultinomialNB and BernoulliNB models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 256 ms, total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Getting cleaned text\n",
    "X_clean = [getCleanReview(i) for i in X_train]\n",
    "Xt_clean = [getCleanReview(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.36 s, sys: 28 ms, total: 2.39 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer()                               #No stop word removal or stemming\n",
    "X_vec = cv.fit_transform(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 s, sys: 7.96 ms, total: 49 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv1 = CountVectorizer(tokenizer=get_useful_words)   #Stop word removal and stemming using our own tokenizer\n",
    "X1_vec = cv1.fit_transform(X_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb  = MultinomialNB()\n",
    "mnb1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training\n",
    "mnb.fit(X_vec,Y_train)\n",
    "mnb1.fit(X1_vec,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.2 ms, sys: 0 ns, total: 3.2 ms\n",
      "Wall time: 2.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#vectorizing test set's 1 example\n",
    "#Following two are vectors of same test example but they have different number of features\n",
    "#as both are generated from different countvectorizer objects.\n",
    "Xt_vec  = cv.transform(Xt_clean[1:2]).toarray()\n",
    "Xt_vec1 = cv1.transform(Xt_clean[1:2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(mnb.predict(Xt_vec[:1])[0])     #without stop word removal or stemming\n",
    "\n",
    "print(mnb1.predict(Xt_vec1[:1])[0])    #with stop word removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy without stemming (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3832\n",
      "CPU times: user 27.5 s, sys: 14.7 ms, total: 27.5 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "itr = 0\n",
    "correct = 0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    itr += 1\n",
    "    Xt_vec = cv.transform(Xt_clean[i:i+1]).toarray()\n",
    "    if Y_test[i] == mnb.predict(Xt_vec)[0]:\n",
    "        correct += 1\n",
    "print('Iterations : %d      Accuracy : %.4f'%(itr,(correct/float(itr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with stop word removal and stemming using own tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3872\n",
      "\n",
      "CPU times: user 2min 35s, sys: 1.99 s, total: 2min 37s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "itr = 0\n",
    "correct = 0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    itr += 1\n",
    "    Xt_vec = cv1.transform(Xt_clean[i:i+1]).toarray()\n",
    "    if Y_test[i] == mnb1.predict(Xt_vec)[0]:\n",
    "        correct += 1\n",
    "    print('Iterations : %d      Accuracy : %.4f'%(itr,(correct/float(itr))),end='\\r')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb  = BernoulliNB()\n",
    "bnb1 = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training\n",
    "bnb.fit(X_vec,Y_train)\n",
    "bnb1.fit(X1_vec,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#vectorizing test set's 1 example\n",
    "#Following two are vectors of same test example but they have different number of features\n",
    "#as both are generated from different countvectorizer objects.\n",
    "Xt_vec  = cv.transform(Xt_clean[1:2]).toarray()\n",
    "Xt_vec1 = cv1.transform(Xt_clean[1:2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(bnb.predict(Xt_vec[:1])[0])     #without stop word removal or stemming\n",
    "\n",
    "print(bnb1.predict(Xt_vec1[:1])[0])    #with stop word removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy without stemming (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3708\n",
      "\n",
      "CPU times: user 3min, sys: 2.4 s, total: 3min 2s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "itr = 0\n",
    "correct = 0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    itr += 1\n",
    "    Xt_vec = cv.transform(Xt_clean[i:i+1]).toarray()\n",
    "    if Y_test[i] == bnb.predict(Xt_vec)[0]:\n",
    "        correct += 1\n",
    "    print('Iterations : %d      Accuracy : %.4f'%(itr,(correct/float(itr))),end='\\r')\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with stop word removal and stemming using own tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 25000      Accuracy : 0.3747\n",
      "\n",
      "CPU times: user 4min 50s, sys: 2.53 s, total: 4min 53s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "itr = 0\n",
    "correct = 0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    itr += 1\n",
    "    Xt_vec = cv1.transform(Xt_clean[i:i+1]).toarray()\n",
    "    if Y_test[i] == bnb1.predict(Xt_vec)[0]:\n",
    "        correct += 1\n",
    "    print('Iterations : %d      Accuracy : %.4f'%(itr,(correct/float(itr))),end='\\r')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
